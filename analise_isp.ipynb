{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43945dc8",
   "metadata": {},
   "source": [
    "# üìä An√°lise do Mercado de Banda Larga ‚Äî ISPs no Brasil\n",
    "\n",
    "## Contexto\n",
    "Um fundo de investimento hipot√©tico avalia entrar no mercado de banda larga brasileiro por meio da **aquisi√ß√£o de Provedores de Servi√ßos de Internet (ISPs)**.  \n",
    "O objetivo √© entender o **potencial de crescimento** desse mercado, considerando **tecnologias** (Fibra, Cobre etc.) e **regi√µes** (UFs, macrorregi√µes e Brasil como um todo).\n",
    "\n",
    "---\n",
    "\n",
    "## Fontes de Dados\n",
    "- **Anatel** ‚Äî acessos de banda larga por munic√≠pio, empresa, tecnologia e velocidade.  \n",
    "- **IBGE** ‚Äî estat√≠sticas de domic√≠lios (totais e ocupados), popula√ß√£o e densidade.  \n",
    "\n",
    "Os dados foram processados em camadas:\n",
    "- **RAW** ‚Üí arquivos originais (CSV/Parquet).  \n",
    "- **TRUSTED** ‚Üí dados limpos e normalizados (Anatel particionado por ano/UF, IBGE consolidado).  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5df179",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================\n",
    "# Imports\n",
    "# =====================\n",
    "import os, glob, gc, shutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "# Arrow para escrita incremental de Parquet\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow.dataset as ds\n",
    "\n",
    "# DuckDB para para o Merged dos arquivos Anatel\n",
    "import duckdb, os\n",
    "\n",
    "# Mapa de UF a partir do prefixo do c√≥digo de munic√≠pio (IBGE)\n",
    "UF_MAP = {\n",
    "    11:'RO',12:'AC',13:'AM',14:'RR',15:'PA',16:'AP',17:'TO',\n",
    "    21:'MA',22:'PI',23:'CE',24:'RN',25:'PB',26:'PE',27:'AL',\n",
    "    28:'SE',29:'BA',31:'MG',32:'ES',33:'RJ',35:'SP',41:'PR',\n",
    "    42:'SC',43:'RS',50:'MS',51:'MT',52:'GO',53:'DF'\n",
    "}\n",
    "\n",
    "# Colunas esperadas na Anatel (com base no exemplo)\n",
    "ANATEL_COLS = [\n",
    "    'cnpj','empresa','grupo_economico_anatel','porte_operadora_anatel','cod_mun',\n",
    "    'faixa_de_velocidade','velocidade','tecnologia','meio_de_acesso','tipo_de_pessoa',\n",
    "    'tipo_de_produto','banda_larga','data','grupo_tecnologia','grupo_economico',\n",
    "    'grupo_operadora','porte_operadora','ano'\n",
    "]\n",
    "\n",
    "ANATEL_DTYPES_READ = {c:'string' for c in ANATEL_COLS}  # leitura robusta; convertemos depois"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321e9ba7",
   "metadata": {},
   "source": [
    "## Pipeline RAW para TRUSTED\n",
    "\n",
    "**Anatel (CSV, 17 arquivos) e IBGE (Parquet)** ‚Äî processamento **separado**, em **chunks** e grava√ß√£o direta em **Parquet √∫nico** por fonte, para reduzir uso de mem√≥ria.\n",
    "\n",
    "- **RAW**: dados brutos (sem altera√ß√µes)\n",
    "- **TRUSTED**: dados limpos e consolidados  \n",
    "  - `trusted/anatel/anatel_clean.parquet` (**um √∫nico arquivo**, gravado incrementalmente)\n",
    "  - `trusted/ibge/ibge_domicilios_clean.parquet` (**um √∫nico arquivo**, gravado incrementalmente)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ac2bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================\n",
    "# Configura√ß√£o\n",
    "# =====================\n",
    "\n",
    "# >>> Ajuste estes caminhos conforme seu ambiente <<<\n",
    "RAW_ANATEL_DIR = Path(r'raw/tabelas_anatel') # pasta com os CSVs originais\n",
    "RAW_IBGE_PARQUET = Path(r'raw/tabelas_ibge')  # parquet original do IBGE\n",
    "\n",
    "TRUSTED_DIR = Path('./trusted')\n",
    "TRUSTED_ANATEL_PATH = TRUSTED_DIR / 'anatel' / 'anatel_clean.parquet'\n",
    "TRUSTED_IBGE_PATH   = TRUSTED_DIR / 'ibge' / 'ibge.parquet'\n",
    "\n",
    "CHUNK_SIZE = 500_000   # linhas por chunk para CSVs da Anatel (ajuste conforme sua m√°quina)\n",
    "\n",
    "# Estrutura de sa√≠da\n",
    "(TRUSTED_DIR / 'anatel').mkdir(parents=True, exist_ok=True)\n",
    "(TRUSTED_DIR / 'ibge').mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print('RAW_ANATEL_DIR :', RAW_ANATEL_DIR.resolve())\n",
    "print('RAW_IBGE_PARQUET:', RAW_IBGE_PARQUET.resolve())\n",
    "print('TRUSTED_ANATEL_PATH:', TRUSTED_ANATEL_PATH.resolve())\n",
    "print('TRUSTED_IBGE_PATH  :', TRUSTED_IBGE_PATH.resolve())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ae09e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =====================\n",
    "# Fun√ß√µes de limpeza (operam por CHUNK)\n",
    "# =====================\n",
    "def to_upper_strip(series: pd.Series) -> pd.Series:\n",
    "    s = series.astype('string')\n",
    "    s = s.str.normalize('NFKC').str.strip().str.upper()\n",
    "    return s\n",
    "\n",
    "def clean_anatel_chunk(df_raw: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Garante colunas esperadas\n",
    "    for c in ANATEL_COLS:\n",
    "        if c not in df_raw.columns:\n",
    "            df_raw[c] = pd.NA\n",
    "    df = df_raw[ANATEL_COLS].copy()\n",
    "\n",
    "    # Strings normalizadas\n",
    "    str_cols = [\n",
    "        'cnpj','empresa','grupo_economico_anatel','porte_operadora_anatel',\n",
    "        'faixa_de_velocidade','tecnologia','meio_de_acesso','tipo_de_pessoa',\n",
    "        'tipo_de_produto','grupo_tecnologia','grupo_economico','grupo_operadora','porte_operadora'\n",
    "    ]\n",
    "    for c in str_cols:\n",
    "        df[c] = to_upper_strip(df[c])\n",
    "\n",
    "    # Num√©ricos / datas\n",
    "    df['velocidade']   = pd.to_numeric(df['velocidade'], errors='coerce')\n",
    "    df['banda_larga']  = pd.to_numeric(df['banda_larga'], errors='coerce')\n",
    "    df['ano']          = pd.to_numeric(df['ano'], errors='coerce').astype('Int64')\n",
    "    df['cod_mun']      = pd.to_numeric(df['cod_mun'], errors='coerce').astype('Int64')\n",
    "    df['data']         = pd.to_datetime(df['data'], errors='coerce')\n",
    "\n",
    "    # Se ano faltar, puxa de data\n",
    "    if 'ano' in df.columns:\n",
    "        df['ano'] = df['ano'].fillna(df['data'].dt.year).astype('Int64')\n",
    "\n",
    "    # Regras simples\n",
    "    df['banda_larga'] = df['banda_larga'].where(df['banda_larga'] >= 0, np.nan)\n",
    "    df['velocidade']  = df['velocidade'].where(df['velocidade']  >= 0, np.nan)\n",
    "\n",
    "    # UF de cod_mun\n",
    "    df['uf_cod'] = (df['cod_mun'] // 100000).astype('Int64')\n",
    "    df['uf']     = df['uf_cod'].map(UF_MAP)\n",
    "\n",
    "    # Remove inv√°lidos essenciais\n",
    "    df = df.dropna(subset=['cod_mun']).copy()\n",
    "\n",
    "    # Ordena√ß√£o/duplicatas leves por chunk (dedup global √© caro; faremos b√°sico)\n",
    "    sort_cols = ['ano','data','cod_mun','empresa','grupo_tecnologia','faixa_de_velocidade']\n",
    "    df = df.sort_values(sort_cols, na_position='last')\n",
    "    df = df.drop_duplicates(subset=['ano','cod_mun','empresa','grupo_tecnologia','faixa_de_velocidade','velocidade','data'], keep='last')\n",
    "\n",
    "    # Reordenar colunas\n",
    "    ordered = [\n",
    "        'ano','data','uf','cod_mun','empresa','grupo_economico','grupo_economico_anatel',\n",
    "        'grupo_operadora','porte_operadora','porte_operadora_anatel',\n",
    "        'grupo_tecnologia','tecnologia','meio_de_acesso','faixa_de_velocidade','velocidade',\n",
    "        'tipo_de_pessoa','tipo_de_produto','banda_larga','cnpj','uf_cod'\n",
    "    ]\n",
    "    keep = [c for c in ordered if c in df.columns]\n",
    "    return df[keep]\n",
    "\n",
    "def clean_ibge_batch_pdf(batch_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = batch_df.copy()\n",
    "    df['cod_mun'] = pd.to_numeric(df['cod_mun'], errors='coerce').astype('Int64')\n",
    "    for c in ['populacao','dom_tot','dom_part_perm_ocup','pop_dom_part_perm_ocup','pop_por_dom_part_perm_ocup']:\n",
    "        if c in df.columns:\n",
    "            df[c] = pd.to_numeric(df[c], errors='coerce')\n",
    "    df = df.dropna(subset=['cod_mun']).copy()\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c460587c",
   "metadata": {},
   "source": [
    "### 1) Anatel RAW ‚Üí TRUSTED (chunked, single Parquet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450e9e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coleta todos os CSVs\n",
    "csv_paths = sorted([str(p) for p in RAW_ANATEL_DIR.glob('*.csv')])\n",
    "assert len(csv_paths) > 0, \"Nenhum CSV encontrado em RAW_ANATEL_DIR. Verifique o caminho: RAW_ANATEL_DIR\"\n",
    "\n",
    "# Base de sa√≠da (dataset particionado)\n",
    "TRUSTED_ANATEL_PART_DIR = TRUSTED_ANATEL_PATH\n",
    "\n",
    "# Limpa diret√≥rio particionado anterior (se existir) para evitar mistura de vers√µes\n",
    "if TRUSTED_ANATEL_PART_DIR.exists():\n",
    "    shutil.rmtree(TRUSTED_ANATEL_PART_DIR)\n",
    "TRUSTED_ANATEL_PART_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "total_rows = 0\n",
    "file_counter = 0\n",
    "\n",
    "for path in csv_paths:\n",
    "    print(f\"[Anatel] Processando arquivo: {path}\")\n",
    "    chunk_iter = pd.read_csv(\n",
    "        path,\n",
    "        dtype=ANATEL_DTYPES_READ,\n",
    "        chunksize=CHUNK_SIZE,\n",
    "        low_memory=True\n",
    "    )\n",
    "\n",
    "    for i, chunk in enumerate(chunk_iter, start=1):\n",
    "        cleaned = clean_anatel_chunk(chunk)\n",
    "\n",
    "        # Garante que as chaves de parti√ß√£o existam\n",
    "        cleaned = cleaned.dropna(subset=[\"ano\", \"uf\"]).copy()\n",
    "\n",
    "        # Agrupa por parti√ß√£o e escreve cada grupo em um arquivo parquet separado\n",
    "        if len(cleaned):\n",
    "            for (ano_val, uf_val), gdf in cleaned.groupby([\"ano\", \"uf\"], as_index=False, sort=False):\n",
    "                # Caminho da parti√ß√£o: ano=YYYY/uf=XX/\n",
    "                part_dir = TRUSTED_ANATEL_PART_DIR / f\"ano={int(ano_val)}\" / f\"uf={str(uf_val)}\"\n",
    "                part_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "                # Nome de arquivo √∫nico por chunk/grupo (evita colis√£o)\n",
    "                file_counter += 1\n",
    "                filename = f\"part-{file_counter:08d}.parquet\"\n",
    "                out_path = part_dir / filename\n",
    "\n",
    "                # Pandas -> Arrow Table -> Parquet\n",
    "                table = pa.Table.from_pandas(gdf, preserve_index=False)\n",
    "                pq.write_table(\n",
    "                    table,\n",
    "                    out_path.as_posix(),\n",
    "                    compression=\"zstd\",\n",
    "                    use_dictionary=True\n",
    "                )\n",
    "\n",
    "                # Libera mem√≥ria\n",
    "                del gdf, table\n",
    "\n",
    "            total_rows += len(cleaned)\n",
    "\n",
    "        # Libera mem√≥ria entre chunks\n",
    "        del chunk, cleaned\n",
    "        if i % 5 == 0:\n",
    "            gc.collect()\n",
    "\n",
    "    gc.collect()\n",
    "\n",
    "print(f\"[Anatel] Dataset particionado salvo em: {TRUSTED_ANATEL_PART_DIR}\")\n",
    "print(f\"[Anatel] Linhas escritas (aprox): {total_rows:,}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfaae673",
   "metadata": {},
   "source": [
    "### 2) IBGE RAW ‚Üí TRUSTED (streaming Parquet ‚Üí Parquet √∫nico)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da1205d",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert RAW_IBGE_PARQUET.exists(), \"Arquivo RAW do IBGE n√£o encontrado.\"\n",
    "\n",
    "# Seleciona apenas colunas de interesse para reduzir mem√≥ria\n",
    "IBGE_COLS = [\n",
    "    'cod_mun','populacao','dom_tot','dom_part_perm_ocup',\n",
    "    'pop_dom_part_perm_ocup','pop_por_dom_part_perm_ocup'\n",
    "]\n",
    "\n",
    "dataset = ds.dataset(RAW_IBGE_PARQUET.as_posix(), format='parquet')\n",
    "\n",
    "# Compat: algumas vers√µes t√™m .scanner(), outras exigem ds.Scanner.from_dataset(...)\n",
    "if hasattr(dataset, \"scanner\"):\n",
    "    scanner = dataset.scanner(columns=IBGE_COLS)\n",
    "else:\n",
    "    scanner = ds.Scanner.from_dataset(dataset, columns=IBGE_COLS)\n",
    "\n",
    "# Remove arquivo anterior\n",
    "if TRUSTED_IBGE_PATH.exists():\n",
    "    TRUSTED_IBGE_PATH.unlink()\n",
    "\n",
    "writer = None\n",
    "total_rows_ibge = 0\n",
    "\n",
    "for record_batch in scanner.to_batches():\n",
    "    # batch -> pandas -> limpeza -> Arrow Table\n",
    "    pd_batch = record_batch.to_pandas(types_mapper=pd.ArrowDtype)\n",
    "    pd_clean = clean_ibge_batch_pdf(pd_batch)\n",
    "    table = pa.Table.from_pandas(pd_clean, preserve_index=False)\n",
    "\n",
    "    # Cria o writer somente quando j√° soubermos o schema\n",
    "    if writer is None:\n",
    "        writer = pq.ParquetWriter(\n",
    "            TRUSTED_IBGE_PATH.as_posix(),\n",
    "            table.schema,\n",
    "            compression=\"zstd\",\n",
    "            use_dictionary=True\n",
    "        )\n",
    "\n",
    "    writer.write_table(table)\n",
    "    total_rows_ibge += len(pd_clean)\n",
    "\n",
    "    # Libera mem√≥ria\n",
    "    del record_batch, pd_batch, pd_clean, table\n",
    "    gc.collect()\n",
    "\n",
    "# Fecha o writer se foi aberto (dataset pode estar vazio)\n",
    "if writer is not None:\n",
    "    writer.close()\n",
    "\n",
    "print(f\"IBGE TRUSTED salvo em: {TRUSTED_IBGE_PATH}\")\n",
    "print(f\"Linhas escritas (aprox): {total_rows_ibge:,}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd77a49",
   "metadata": {},
   "source": [
    "\n",
    "### Observa√ß√µes de performance\n",
    "- **Chunking (Anatel)**: leitura e limpeza em blocos de `CHUNK_SIZE` linhas; cada bloco √© gravado diretamente no Parquet final via `ParquetWriter` (evita DataFrame gigante em mem√≥ria).\n",
    "- **Streaming (IBGE)**: leitura **em batches** do Parquet via `pyarrow.dataset`, limpeza em pandas e escrita incremental em Parquet.\n",
    "- **Tipos**: leitura como `string` e convers√£o pontual reduz erros de parsing e reprocessamentos.\n",
    "- **Coleta de lixo (`gc.collect()`)**: for√ßada ap√≥s blocos para liberar mem√≥ria.\n",
    "- **Resultado**: Com a convers√£o para arquivo parquet, o tamanho dos arquivos da camada `raw` s√£o reduzidos de 4,5GB para apenas 163MB na camada `trusted`. Uma **redu√ß√£o de 96,5%** de espa√ßo em disco.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb02f962",
   "metadata": {},
   "source": [
    "##  An√°lises "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130a8dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup: conex√£o e views\n",
    "import duckdb\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "\n",
    "con = duckdb.connect()\n",
    "con.execute(\"PRAGMA threads=4;\")\n",
    "\n",
    "def pct_formatada(x):\n",
    "    return \"\" if pd.isna(x) else f\"{x:.2f}%\".replace(\".\", \",\")\n",
    "\n",
    "ANATEL_PART_DIR = Path(\"./trusted/anatel_partitioned\").resolve()\n",
    "TRUSTED_IBGE    = Path(\"./trusted/ibge/ibge_domicilios_clean.parquet\").resolve()\n",
    "\n",
    "assert ANATEL_PART_DIR.exists(), \"anatel_partitioned n√£o encontrado.\"\n",
    "assert TRUSTED_IBGE.exists(), \"ibge_domicilios_clean.parquet n√£o encontrado.\"\n",
    "\n",
    "con.execute(f\"\"\"\n",
    "  CREATE OR REPLACE VIEW anatel_raw AS\n",
    "  SELECT * FROM read_parquet('{ANATEL_PART_DIR.as_posix()}/**/*.parquet', hive_partitioning=1);\n",
    "\"\"\")\n",
    "\n",
    "con.execute(f\"\"\"\n",
    "  CREATE OR REPLACE VIEW ibge_raw AS\n",
    "  SELECT * FROM read_parquet('{TRUSTED_IBGE.as_posix()}');\n",
    "\"\"\")\n",
    "\n",
    "# Apenas ISPs, j√° normalizando o texto (TRIM/UPPER) para evitar varia√ß√µes\n",
    "con.execute(\"\"\"\n",
    "    CREATE OR REPLACE VIEW anatel_isp AS\n",
    "    SELECT\n",
    "        cod_mun, uf, ano, data,\n",
    "        grupo_tecnologia, tecnologia, meio_de_acesso,\n",
    "        empresa, cnpj,\n",
    "        UPPER(TRIM(grupo_economico)) AS grupo_economico,\n",
    "        faixa_de_velocidade, velocidade, banda_larga\n",
    "    FROM anatel_raw\n",
    "    WHERE UPPER(TRIM(grupo_economico)) = 'ISP';\n",
    "\"\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0e26c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Views auxiliares: agrega√ß√µes m√≠nimas por munic√≠pio/ano/tecnologia e households do IBGE\n",
    "\n",
    "# assinantes por mun/ano/tec (podemos filtrar ISP depois)\n",
    "con.execute(\"\"\"\n",
    "  CREATE OR REPLACE VIEW vw_mun_ano_tec AS\n",
    "  SELECT\n",
    "    cod_mun,\n",
    "    uf,\n",
    "    ano,\n",
    "    grupo_tecnologia,\n",
    "    SUM(banda_larga) AS assinantes\n",
    "  FROM anatel_raw\n",
    "  GROUP BY 1,2,3,4;\n",
    "\"\"\")\n",
    "\n",
    "# households do IBGE (dom_part_perm_ocup = domic√≠lios particulares permanentes ocupados)\n",
    "con.execute(\"\"\"\n",
    "  CREATE OR REPLACE VIEW vw_households AS\n",
    "  SELECT\n",
    "    cod_mun::INT AS cod_mun,\n",
    "    dom_part_perm_ocup::BIGINT AS dom_ocup\n",
    "  FROM ibge_raw;\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f05f5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Penetra√ß√£o por UF/ano/tecnologia\n",
    "sql_pen = \"\"\"\n",
    "WITH mun_join AS (\n",
    "  SELECT a.cod_mun, a.uf, a.ano, a.grupo_tecnologia, a.assinantes, i.dom_ocup\n",
    "  FROM vw_mun_ano_tec a\n",
    "  LEFT JOIN vw_households i USING (cod_mun)\n",
    "),\n",
    "uf_tec AS (\n",
    "  SELECT\n",
    "    uf, ano, grupo_tecnologia,\n",
    "    SUM(assinantes) AS assinantes,\n",
    "    SUM(dom_ocup)   AS dom_ocup\n",
    "  FROM mun_join\n",
    "  GROUP BY 1,2,3\n",
    ")\n",
    "SELECT\n",
    "  uf, ano, grupo_tecnologia,\n",
    "  assinantes, dom_ocup,\n",
    "  CASE WHEN dom_ocup > 0 THEN 100.0 * assinantes / dom_ocup END AS penetracao_pct\n",
    "FROM uf_tec\n",
    "ORDER BY ano, uf, grupo_tecnologia;\n",
    "\"\"\"\n",
    "df_pen = con.execute(sql_pen).df()\n",
    "df_pen.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5c72a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Crescimento/CAGR por tecnologia e regi√£o\n",
    "sql_cagr_reg = \"\"\"\n",
    "WITH regiao_map AS (\n",
    "  SELECT\n",
    "    DISTINCT uf,\n",
    "    CASE\n",
    "      WHEN uf IN ('RO','AC','AM','RR','PA','AP','TO') THEN 'Norte'\n",
    "      WHEN uf IN ('MA','PI','CE','RN','PB','PE','AL','SE','BA') THEN 'Nordeste'\n",
    "      WHEN uf IN ('MG','ES','RJ','SP') THEN 'Sudeste'\n",
    "      WHEN uf IN ('PR','SC','RS') THEN 'Sul'\n",
    "      WHEN uf IN ('MS','MT','GO','DF') THEN 'Centro-Oeste'\n",
    "    END AS regiao\n",
    "  FROM anatel_isp\n",
    "),\n",
    "agg AS (\n",
    "  SELECT r.regiao, a.ano, a.grupo_tecnologia, SUM(a.banda_larga) AS assinantes\n",
    "  FROM anatel_isp a\n",
    "  JOIN regiao_map r USING (uf)\n",
    "  WHERE ano BETWEEN 2019 AND 2023\n",
    "  GROUP BY 1,2,3\n",
    "),\n",
    "base AS (\n",
    "  SELECT\n",
    "    regiao, grupo_tecnologia,\n",
    "    SUM(CASE WHEN ano=2019 THEN assinantes ELSE 0 END) AS a2019,\n",
    "    SUM(CASE WHEN ano=2023 THEN assinantes ELSE 0 END) AS a2023\n",
    "  FROM agg\n",
    "  GROUP BY 1,2\n",
    ")\n",
    "SELECT\n",
    "  regiao, grupo_tecnologia, a2019, a2023,\n",
    "  (a2023 - a2019) AS crescimento_abs,\n",
    "  CASE WHEN a2019>0 THEN printf('%.2f%%', (POWER(a2023*1.0/a2019, 1.0/4) - 1) * 100) END AS CAGR_2019_2023\n",
    "FROM base\n",
    "ORDER BY regiao, grupo_tecnologia;\n",
    "\"\"\"\n",
    "\n",
    "df_cagr_reg = con.execute(sql_cagr_reg).df()\n",
    "#df_cagr_reg.style.format({\"CAGR_2019_2023\": pct_formatada})\n",
    "#df_cagr_reg.style.format({\"CAGR_2019_2023\": pct_formatada})\n",
    "df_cagr_reg.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91ba36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Market share por UF/ano ‚Äî total e ISPs\n",
    "sql_mshare = \"\"\"\n",
    "WITH total AS (\n",
    "  SELECT uf, ano, SUM(banda_larga) AS assin_total\n",
    "  FROM anatel_raw\n",
    "  GROUP BY 1,2\n",
    "),\n",
    "por_grupo AS (\n",
    "  SELECT uf, ano, UPPER(TRIM(grupo_economico)) AS grupo_economico, SUM(banda_larga) AS assin_grupo\n",
    "  FROM anatel_raw\n",
    "  GROUP BY 1,2,3\n",
    ")\n",
    "SELECT\n",
    "  p.uf, p.ano, p.grupo_economico, p.assin_grupo, t.assin_total,\n",
    "  CASE WHEN t.assin_total>0 THEN 100.0 * p.assin_grupo / t.assin_total END AS market_share_pct\n",
    "FROM por_grupo p\n",
    "JOIN total t USING (uf, ano)\n",
    "ORDER BY ano DESC, uf, market_share_pct DESC;\n",
    "\"\"\"\n",
    "df_mshare = con.execute(sql_mshare).df()\n",
    "\n",
    "# Filtra 2023 e normaliza grupo\n",
    "df_2023 = df_mshare[df_mshare[\"ano\"] == 2023].copy()\n",
    "df_2023[\"grupo_economico\"] = df_2023[\"grupo_economico\"].str.upper().str.strip()\n",
    "\n",
    "# Share do ISP por UF\n",
    "isp = (\n",
    "    df_2023[df_2023[\"grupo_economico\"] == \"ISP\"]\n",
    "    .groupby(\"uf\", as_index=False)[\"market_share_pct\"].sum()\n",
    "    .rename(columns={\"market_share_pct\": \"ISP\"})\n",
    ")\n",
    "\n",
    "# Conjunto completo de UFs presentes em 2023\n",
    "all_ufs = sorted(df_2023[\"uf\"].dropna().unique())  # ordem alfab√©tica\n",
    "\n",
    "# Reindexa para garantir todas as UFs e calcula \"Outros\", ordena por ISP\n",
    "isp = isp.set_index(\"uf\").reindex(all_ufs, fill_value=0).reset_index()\n",
    "isp[\"OUTROS\"] = (100 - isp[\"ISP\"]).clip(lower=0, upper=100)\n",
    "isp = isp.sort_values(by=\"ISP\", ascending=False)  # Ordena por ISP\n",
    "\n",
    "# --- Plot: barras empilhadas (percentual) ---\n",
    "plt.figure(figsize=(21, 9))\n",
    "bars_outros = plt.bar(isp[\"uf\"], isp[\"OUTROS\"], label=\"Outros\")  # legenda\n",
    "bars_isp = plt.bar(isp[\"uf\"], isp[\"ISP\"], bottom=isp[\"OUTROS\"], label=\"ISP\")\n",
    "\n",
    "# Adiciona porcentagens dentro das barras\n",
    "for bars in [bars_outros, bars_isp]:\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        if height > 0:  # Apenas se houver altura para evitar sobreposi√ß√£o\n",
    "            plt.text(bar.get_x() + bar.get_width() / 2, bar.get_y() + height / 2,\n",
    "                     f'{height:.1f}%',\n",
    "                     ha='center', va='center', rotation=0, color='white', fontsize=10)\n",
    "\n",
    "# Remove os valores do eixo y\n",
    "plt.yticks([])\n",
    "\n",
    "plt.title(\"Market share por UF ‚Äî 2023 (ISP √ó Outros)\")\n",
    "plt.ylabel(\"Participa√ß√£o (%)\")\n",
    "plt.xlabel(\"UF\")\n",
    "plt.grid(True, axis=\"y\", alpha=0.25)\n",
    "plt.xticks(rotation=0)\n",
    "\n",
    "# Ajusta as margens para reduzir o espa√ßo externo\n",
    "plt.margins(x=0.01, y=0.09)  # Reduz a margem horizontal\n",
    "plt.tight_layout()\n",
    "\n",
    "# Legenda clara com r√≥tulos definidos nos bars\n",
    "plt.legend(loc=\"upper right\", frameon=False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44622543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Tamanho do player ISP ‚Äî assinantes totais + n¬∫ de munic√≠pios atendidos (2023)\n",
    "\n",
    "sql_size = \"\"\"\n",
    "WITH base AS (\n",
    "  SELECT\n",
    "    UPPER(TRIM(grupo_economico)) AS grupo_economico,\n",
    "    UPPER(TRIM(empresa)) AS empresa,\n",
    "    cod_mun, ano, SUM(banda_larga) AS assin\n",
    "  FROM anatel_isp\n",
    "  WHERE ano = 2023\n",
    "  GROUP BY 1,2,3,4\n",
    ")\n",
    "SELECT\n",
    "  empresa,\n",
    "  SUM(assin) AS assinantes_2023,\n",
    "  COUNT(DISTINCT cod_mun) AS n_municipios\n",
    "FROM base\n",
    "GROUP BY 1\n",
    "ORDER BY assinantes_2023 DESC\n",
    "LIMIT 50;\n",
    "\"\"\"\n",
    "df_size = con.execute(sql_size).df()\n",
    "df_size.style.format({\"assinantes_2023\": pct_formatada})\n",
    "df_size.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1e10ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) Crescimento por tecnologia (Brasil) 2019‚Üí2023\n",
    "df_tec_br = con.execute(\"\"\"\n",
    "WITH agg AS (\n",
    "  SELECT ano, grupo_tecnologia, SUM(banda_larga) AS assin\n",
    "  FROM anatel_raw\n",
    "  WHERE ano BETWEEN 2019 AND 2023\n",
    "  GROUP BY 1,2\n",
    ")\n",
    "SELECT * FROM agg ORDER BY grupo_tecnologia, ano;\n",
    "\"\"\").df()\n",
    "\n",
    "pivot = df_tec_br.pivot(index='ano', columns='grupo_tecnologia', values='assin')\n",
    "ax = pivot.plot(figsize=(9,5))\n",
    "plt.title(\"Assinantes por tecnologia ‚Äî Brasil (2019‚Äì2023)\")\n",
    "plt.xlabel(\"Ano\"); plt.ylabel(\"Assinantes\"); plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b1ae37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) Forecast 2024: aplica CAGR (2020‚Üí2023) por UF √ó tecnologia na base de 2023\n",
    "sql_fc = \"\"\"\n",
    "WITH agg AS (\n",
    "  SELECT uf, ano, grupo_tecnologia, SUM(banda_larga) AS assin\n",
    "  FROM anatel_raw\n",
    "  WHERE ano BETWEEN 2020 AND 2023\n",
    "  GROUP BY 1,2,3\n",
    "),\n",
    "pvt AS (\n",
    "  SELECT\n",
    "    uf, grupo_tecnologia,\n",
    "    SUM(CASE WHEN ano=2020 THEN assin ELSE 0 END) AS a2020,\n",
    "    SUM(CASE WHEN ano=2023 THEN assin ELSE 0 END) AS a2023\n",
    "  FROM agg\n",
    "  GROUP BY 1,2\n",
    "),\n",
    "cagr AS (\n",
    "  SELECT\n",
    "    uf, grupo_tecnologia, a2020, a2023,\n",
    "    CASE WHEN a2020>0 THEN POWER(a2023*1.0/a2020, 1.0/3) - 1 END AS cagr_2020_2023\n",
    "  FROM pvt\n",
    "),\n",
    "base_2023 AS (\n",
    "  SELECT uf, grupo_tecnologia, SUM(banda_larga) AS assin_2023\n",
    "  FROM anatel_raw\n",
    "  WHERE ano=2023\n",
    "  GROUP BY 1,2\n",
    ")\n",
    "SELECT\n",
    "  b.uf, b.grupo_tecnologia,\n",
    "  b.assin_2023,\n",
    "  c.cagr_2020_2023,\n",
    "  ROUND(b.assin_2023 * (1 + COALESCE(c.cagr_2020_2023,0))) AS forecast_2024\n",
    "FROM base_2023 b\n",
    "LEFT JOIN cagr c USING (uf, grupo_tecnologia)\n",
    "ORDER BY b.uf, b.grupo_tecnologia;\n",
    "\"\"\"\n",
    "df_fc = con.execute(sql_fc).df()\n",
    "df_fc.head(20)\n",
    "\n",
    "# -------- Gr√°fico 1: Brasil por tecnologia (crescimento % 2024 vs 2023) --------\n",
    "br_tec = (\n",
    "    df_fc.groupby(\"grupo_tecnologia\", as_index=False)[[\"assin_2023\",\"forecast_2024\"]].sum()\n",
    ")\n",
    "br_tec[\"crescimento_pct\"] = (br_tec[\"forecast_2024\"]/br_tec[\"assin_2023\"] - 1) * 100\n",
    "\n",
    "plt.figure(figsize=(9,5))\n",
    "# barras do crescimento %\n",
    "plt.bar(br_tec[\"grupo_tecnologia\"], br_tec[\"crescimento_pct\"])\n",
    "plt.title(\"Previs√£o 2024 ‚Äî Crescimento % por tecnologia (Brasil)\")\n",
    "plt.ylabel(\"Crescimento % (2024 vs 2023)\")\n",
    "plt.xlabel(\"Tecnologia\")\n",
    "# r√≥tulos sobre as barras\n",
    "for x, y in zip(br_tec[\"grupo_tecnologia\"], br_tec[\"crescimento_pct\"]):\n",
    "    plt.text(x, y, f\"{y:.1f}%\", ha=\"center\", va=\"bottom\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# -------- Gr√°fico 2: Heatmap UF x tecnologia (top 15 UFs por base 2023) --------\n",
    "df_fc = df_fc.copy()\n",
    "df_fc[\"crescimento_pct\"] = (df_fc[\"forecast_2024\"]/df_fc[\"assin_2023\"] - 1) * 100\n",
    "\n",
    "# Seleciona top 15 UFs por base 2023 (soma das tecnologias)\n",
    "ufs_top = (\n",
    "    df_fc.groupby(\"uf\", as_index=False)[\"assin_2023\"].sum()\n",
    "    .sort_values(\"assin_2023\", ascending=False)\n",
    "    .head(15)[\"uf\"]\n",
    "    .tolist()\n",
    ")\n",
    "sub = df_fc[df_fc[\"uf\"].isin(ufs_top)]\n",
    "\n",
    "# Pivot para heatmap (linhas: UF, colunas: tecnologia)\n",
    "heat = sub.pivot_table(\n",
    "    index=\"uf\", columns=\"grupo_tecnologia\",\n",
    "    values=\"crescimento_pct\", aggfunc=\"mean\"\n",
    ").sort_index()\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.imshow(heat.values, aspect=\"auto\")  # usa colormap padr√£o\n",
    "plt.title(\"Previs√£o 2024 ‚Äî Crescimento % por UF √ó tecnologia (top 15 UFs)\")\n",
    "plt.xlabel(\"Tecnologia\")\n",
    "plt.ylabel(\"UF\")\n",
    "# ticks\n",
    "plt.xticks(range(len(heat.columns)), heat.columns, rotation=45, ha=\"right\")\n",
    "plt.yticks(range(len(heat.index)), heat.index)\n",
    "# anota valores (opcional, com 1 decimal)\n",
    "for i in range(heat.shape[0]):\n",
    "    for j in range(heat.shape[1]):\n",
    "        val = heat.values[i, j]\n",
    "        if pd.notnull(val):\n",
    "            plt.text(j, i, f\"{val:.1f}\", ha=\"center\", va=\"center\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e6cb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7) ISPs-alvo\n",
    "# Crit√©rios:\n",
    "# - >= 50 mil assinantes (2023)\n",
    "# - >= 50 munic√≠pios (2023)\n",
    "# - crescimento absoluto 2019‚Üí2023 > 20%\n",
    "# - CAGR 2019‚Üí2023 >= 9% a.a.\n",
    "# - mix de FIBRA (meio_de_acesso='FIBRA') em 2023 >= 50%\n",
    "\n",
    "isps_alvo = \"\"\"\n",
    "WITH base AS (  -- agrega√ß√£o por empresa, ano e meio_de_acesso\n",
    "  SELECT\n",
    "    UPPER(TRIM(grupo_economico)) AS grupo_economico,\n",
    "    UPPER(TRIM(empresa))         AS empresa,\n",
    "    ano,\n",
    "    UPPER(TRIM(meio_de_acesso))  AS meio_de_acesso,\n",
    "    SUM(banda_larga)             AS assin\n",
    "  FROM anatel_isp\n",
    "  WHERE ano BETWEEN 2019 AND 2023\n",
    "  GROUP BY 1,2,3,4\n",
    "),\n",
    "split AS (      -- totais e fibra por empresa/ano\n",
    "  SELECT\n",
    "    empresa,\n",
    "    ano,\n",
    "    SUM(assin)                                           AS assin_total,\n",
    "    SUM(CASE WHEN meio_de_acesso='FIBRA' THEN assin ELSE 0 END) AS assin_fibra\n",
    "  FROM base\n",
    "  GROUP BY 1,2\n",
    "),\n",
    "pvt1 AS (       -- consolida 2019 e 2023\n",
    "  SELECT\n",
    "    empresa,\n",
    "    SUM(CASE WHEN ano=2019 THEN assin_total ELSE 0 END) AS a2019,\n",
    "    SUM(CASE WHEN ano=2023 THEN assin_total ELSE 0 END) AS a2023,\n",
    "    SUM(CASE WHEN ano=2023 THEN assin_fibra ELSE 0 END) AS fibra_2023\n",
    "  FROM split\n",
    "  GROUP BY 1\n",
    "),\n",
    "footprint AS (  -- n¬∫ de munic√≠pios atendidos em 2023\n",
    "  SELECT\n",
    "    UPPER(TRIM(empresa)) AS empresa,\n",
    "    COUNT(DISTINCT cod_mun) AS n_municipios\n",
    "  FROM anatel_isp\n",
    "  WHERE ano=2023\n",
    "  GROUP BY 1\n",
    ")\n",
    "SELECT\n",
    "  p.empresa,\n",
    "  p.a2019,\n",
    "  p.a2023,\n",
    "  (p.a2023 - p.a2019) AS crescimento_abs,\n",
    "  CASE WHEN p.a2019>0 THEN printf('%.2f%%', POWER(p.a2023*1.0/p.a2019, 1.0/4) - 1) END AS cagr_aa,\n",
    "  CASE WHEN p.a2023>0 THEN printf('%.2f%%', 100.0 * p.fibra_2023 / p.a2023) END AS fibra_share_2023_pct,\n",
    "  f.n_municipios\n",
    "FROM pvt1 p\n",
    "LEFT JOIN footprint f USING (empresa)\n",
    "WHERE p.a2023 >= 50000\n",
    "  AND p.a2019 >= 100\n",
    "  AND f.n_municipios >= 50\n",
    "  AND (p.a2023 - p.a2019) > 0.20 * p.a2019\n",
    "  AND (CASE WHEN p.a2019>0 THEN POWER(p.a2023*1.0/p.a2019, 1.0/4) - 1 END) >= 0.9\n",
    "  AND (CASE WHEN p.a2023>0 THEN 100.0 * p.fibra_2023 / p.a2023 END) >= 50\n",
    "ORDER BY p.a2023 DESC;\n",
    "\"\"\"\n",
    "\n",
    "df_short = con.execute(isps_alvo).df()\n",
    "display(df_short)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d64cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 8) Domic√≠lios com e sem internet (Brasil, base 2023) + % formatadas\n",
    "\n",
    "ANO_REF = 2023  # ajuste se quiser outro ano\n",
    "\n",
    "sql = f\"\"\"\n",
    "WITH assin_mun AS (\n",
    "  SELECT\n",
    "    cod_mun,\n",
    "    SUM(banda_larga) AS assinantes\n",
    "  FROM anatel_raw\n",
    "  WHERE ano = {ANO_REF}\n",
    "  GROUP BY cod_mun\n",
    "),\n",
    "ibge AS (\n",
    "  SELECT\n",
    "    cod_mun::INT AS cod_mun,\n",
    "    dom_tot::BIGINT AS dom_tot\n",
    "  FROM ibge_raw\n",
    ")\n",
    "SELECT\n",
    "  SUM(dom_tot)                                               AS dom_tot_brasil,\n",
    "  SUM(LEAST(COALESCE(a.assinantes,0), COALESCE(i.dom_tot,0))) AS dom_com_internet,\n",
    "  SUM(GREATEST(COALESCE(i.dom_tot,0) - LEAST(COALESCE(a.assinantes,0), COALESCE(i.dom_tot,0)), 0)) AS dom_sem_internet\n",
    "FROM ibge i\n",
    "LEFT JOIN assin_mun a USING (cod_mun);\n",
    "\"\"\"\n",
    "\n",
    "df_br = con.execute(sql).df()\n",
    "\n",
    "# calcula % e formata com v√≠rgula\n",
    "tot = int(df_br.loc[0, \"dom_tot_brasil\"])\n",
    "com = int(df_br.loc[0, \"dom_com_internet\"])\n",
    "sem = int(df_br.loc[0, \"dom_sem_internet\"])\n",
    "\n",
    "pct_com = (com / tot * 100) if tot else 0.0\n",
    "pct_sem = (sem / tot * 100) if tot else 0.0\n",
    "\n",
    "def fmt_pct(x):\n",
    "    return f\"{x:.2f}%\".replace(\".\", \",\")\n",
    "\n",
    "resumo = pd.DataFrame([{\n",
    "    \"Ano\": ANO_REF,\n",
    "    \"Domic√≠lios totais (dom_tot)\": f\"{tot:,}\".replace(\",\", \".\"),\n",
    "    \"Com internet (estimado)\": f\"{com:,}\".replace(\",\", \".\"),\n",
    "    \"Sem internet (estimado)\": f\"{sem:,}\".replace(\",\", \".\"),\n",
    "    \"% com internet\": fmt_pct(pct_com),\n",
    "    \"% sem internet\": fmt_pct(pct_sem),\n",
    "}])\n",
    "\n",
    "display(resumo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1bf4429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9) Sum√°rio: principais tabelas para o relat√≥rio\n",
    "print(\"Top 10 UFs por crescimento absoluto 2017‚Üí2023 (todos os players):\")\n",
    "print(con.execute(\"\"\"\n",
    "WITH agg AS (\n",
    "  SELECT uf, ano, SUM(banda_larga) AS assin FROM anatel_raw WHERE ano IN (2017,2023) GROUP BY 1,2\n",
    "),\n",
    "pvt AS (\n",
    "  SELECT uf,\n",
    "         SUM(CASE WHEN ano=2017 THEN assin ELSE 0 END) AS a2017,\n",
    "         SUM(CASE WHEN ano=2023 THEN assin ELSE 0 END) AS a2023\n",
    "  FROM agg GROUP BY 1\n",
    ")\n",
    "SELECT uf, a2017, a2023, (a2023-a2017) AS crescimento_abs\n",
    "FROM pvt WHERE a2017>0 AND a2023>0\n",
    "ORDER BY crescimento_abs DESC LIMIT 10;\n",
    "\"\"\").df())\n",
    "\n",
    "print(\"\\nCAGR 2019‚Üí2023 por tecnologia ‚Äî Brasil:\")\n",
    "print(con.execute(\"\"\"\n",
    "WITH agg AS (\n",
    "  SELECT ano, grupo_tecnologia, SUM(banda_larga) AS assin\n",
    "  FROM anatel_raw WHERE ano BETWEEN 2019 AND 2023 GROUP BY 1,2\n",
    "),\n",
    "pvt AS (\n",
    "  SELECT grupo_tecnologia,\n",
    "         SUM(CASE WHEN ano=2019 THEN assin ELSE 0 END) AS a2019,\n",
    "         SUM(CASE WHEN ano=2023 THEN assin ELSE 0 END) AS a2023\n",
    "  FROM agg GROUP BY 1\n",
    ")\n",
    "SELECT grupo_tecnologia, a2019, a2023,\n",
    "       (a2023-a2019) AS crescimento_abs,\n",
    "       CASE WHEN a2019>0 THEN POWER(a2023*1.0/a2019, 1.0/4) - 1 END AS CAGR\n",
    "FROM pvt ORDER BY CAGR DESC NULLS LAST;\n",
    "\"\"\").df().round(4))\n",
    "\n",
    "print(\"\\nShort-list de ISPs recomendados (regras simples):\")\n",
    "display(df_short.head(15))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5faad740",
   "metadata": {},
   "source": [
    "## Conclus√µes & Recomenda√ß√µes\n",
    "\n",
    "**Mercado & Tecnologia**\n",
    "- Fibra lidera o crescimento de 32,80% de participa√ß√£o para 51,98% de participa√ß√£o em 2022\n",
    "- Regi√µes com maior acelera√ß√£o(CARG): Norte: 14,85%, sul: 9,82%, Sudeste: 3,94%, Nordeste: 2,46%, Centro-Oeste: 2,39%.\n",
    "\n",
    "**Perfil dos ISPs**\n",
    "- ISPs com > X mil assinantes e presen√ßa em ‚â• Y munic√≠pios t√™m melhor escala.\n",
    "- Mix de fibra ‚â• 60% correlaciona com maiores taxas de crescimento.\n",
    "\n",
    "**Short-list de aquisi√ß√µes (2023)**\n",
    "- Crit√©rios: base ‚â• 50k, ‚â• 30 munic√≠pios, CAGR ‚â• 10% a.a., fibra ‚â• 60%.\n",
    "- Candidatos: <3‚Äì5 nomes com n√∫meros-chave>.\n",
    "\n",
    "**Pr√≥ximos passos**\n",
    "- Refinar forecast com modelos (ARIMA/Prophet/regress√£o), vari√°veis macro (renda, densidade domic√≠lios).\n",
    "- Due diligence nos ISPs shortlist: churn, ARPU, capilaridade, qualidade de rede (lat√™ncia/velocidade).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
